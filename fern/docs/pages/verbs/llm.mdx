---
title: Llm
subtitle: Connect a call to AI language model.  
---

```js maxLines=100
session.llm(
{
  vendor: 'openai',
  model: "gpt-4o-realtime-preview-2024-10-01",
  auth: {
    apiKey
  },
  actionHook: '/final',
  eventHook: '/event',
  toolHook: '/toolCall',
  events: [
    'conversation.item.*',
    'response.audio_transcript.done',
    'input_audio_buffer.committed'
  ],
  llmOptions: {
    response_create: {
      modalities: ['text', 'audio'],
      instructions: 'Please assist the user with their request.',
      voice: 'alloy',
      output_audio_format: 'pcm16',
      temperature: 0.8,
      max_output_tokens: 4096,
    },
    session_update: {
      tools: [
        {
          name: 'get_weather',
          type: 'function',
          description: 'Get the weather at a given location',
          parameters: {
            type: 'object',
            properties: {
              location: {
                type: 'string',
                description: 'Location to get the weather from',
              },
              scale: {
                type: 'string',
                enum: ['fahrenheit', 'celsius'],
              },
            },
            required: ['location', 'scale'],
          },
        },
      ],
      tool_choice: 'auto',
      input_audio_transcription: {
        model: 'whisper-1',
      },
      turn_detection: {
        type: 'server_vad',
        threshold: 0.8,
        prefix_padding_ms: 300,
        silence_duration_ms: 500,
      }
    }
  }
})
```

## Parameters

<ParamField path="actionHook" type="string" required={false}>
  Webhook that will be called when the LLM session ends.
</ParamField>

<ParamField path="auth" type="object" required={false}>
  Object containing authentication credentials; format according to the model.
</ParamField>

<ParamField path="connectOptions" type="object" required={false}>
  Object containing information such as the URI to connect to.
</ParamField>

<ParamField path="eventHook" type="string" required={false}>
  Webhook that will be called when a requested LLM event happens (e.g., transcript).
</ParamField>

<ParamField path="events" type="array" required={false}>
  Array of event names listing the events requested (wildcards allowed).
</ParamField>

<ParamField path="llmOptions" type="object" required={false}>
  Object containing instructions for the LLM; format dependent on the LLM model.
</ParamField>

<ParamField path="model" type="string" required={true}>
  Name of the LLM model.
</ParamField>

<ParamField path="toolHook" type="string" required={false}>
  Webhook that will be called when the LLM wants to call a function.
</ParamField>

<ParamField path="vendor" type="string" required={true}>
  Name of the LLM vendor.
</ParamField>


The following LLMs are currently supported:
- OpenAI Realtime API
- Deepgram Voice Agent
- Ultravox
- ElevenLabs

## Example Applications
Please checkout the following example applications:
- for [OpenAI](https://github.com/jambonz/openai-s2s-example)
- for [Deepgram](https://github.com/jambonz/deepgram-voice-agent-example)
- for [Ultravox](https://github.com/jambonz/ultravox-s2s-example)
- for [ElevenLabs](https://github.com/jambonz/elevenlabs-s2s-example)

